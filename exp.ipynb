{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point, LineString\n",
    "from shapely.geometry.polygon import Polygon\n",
    "\n",
    "from geographiclib.geodesic import Geodesic\n",
    "import geopandas as gpd\n",
    "import geopy.distance\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "from scipy import spatial\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_function(func):\n",
    "  def wrapper(*args, **kwargs):\n",
    "    start_time = time.perf_counter()\n",
    "    result = func(*args, **kwargs)\n",
    "    end_time = time.perf_counter()\n",
    "    print(f\"{func.__name__} executed in {end_time - start_time:.4f} seconds\")\n",
    "    return result\n",
    "  return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geojson_to_fgb():\n",
    "  graph_path = Path('data') / 'output_graph' / 'final_graph_cargo_0.0008_0.0016_180' \n",
    "  output_path = Path('data') / 'new_graph'\n",
    "  output_path.mkdir(parents=True, exist_ok=True)\n",
    "  for file in graph_path.rglob('*.geojson'):\n",
    "    parent = file.parents[0].name\n",
    "    new_file = output_path / f'{parent}_{file.stem}.fgb'\n",
    "    if new_file.exists():\n",
    "      continue\n",
    "    print(file)\n",
    "    gdf = gpd.read_file(file)\n",
    "    gdf.to_file(new_file)\n",
    "\n",
    "# convert all geojson to .fgb\n",
    "# reading .fgb file is much faster than reading .geojson \n",
    "# for 11_9 edges data, 2965280 rows in total\n",
    "# .fgb took 13.3531 seconds, .geojson took 47.0435 seconds\n",
    "\n",
    "geojson_to_fgb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time_function\n",
    "def load_file(path: Path) -> gpd.GeoDataFrame:\n",
    "  print(f'geopandas reading file: {path}')\n",
    "  gdf = gpd.read_file(path)\n",
    "  return gdf\n",
    "\n",
    "@time_function\n",
    "def load_edge_and_node_gdfs(graph_path: Path) -> tuple[list[gpd.GeoDataFrame], list[gpd.GeoDataFrame]]:\n",
    "  edge_gdfs, node_gdfs = [], []\n",
    "  for file in graph_path.rglob(\"*.fgb\"):\n",
    "    if file.stem.endswith(\"edges\"):\n",
    "      edge_gdfs.append(load_file(file))\n",
    "    if file.stem.endswith(\"nodes\"):\n",
    "      node_gdfs.append(load_file(file))\n",
    "  return edge_gdfs, node_gdfs\n",
    "\n",
    "def load_edge_from_gpd_row(row, graph: nx.Graph):\n",
    "  start_point, end_point = row[\"geometry\"].coords\n",
    "  # coord looks like (longitude, latitude), note that longitude comes first\n",
    "  graph.add_edge(tuple(start_point), tuple(end_point), weight=row['weight'])\n",
    "\n",
    "def load_node_from_gpd_row(row, graph: nx.Graph):\n",
    "  graph.add_node(row['geometry'].coords[0], **row)\n",
    "\n",
    "@time_function\n",
    "def create_graph_from_node_and_edge_gdfs(graph_path: Path) -> nx.Graph:\n",
    "  graph = nx.Graph() # TODO: consider using directed graph\n",
    "  start_time = time.perf_counter()\n",
    "  \n",
    "  for file in graph_path.rglob(\"*.fgb\"):\n",
    "    if file.stem.endswith(\"nodes\"):\n",
    "      node_gdf = load_file(file)\n",
    "      node_gdf.apply(load_node_from_gpd_row, axis=1, graph=graph)\n",
    "      end_time = time.perf_counter() \n",
    "      print(f\"file:{file} dfSize:{node_gdf.shape[0]} graphSize:{graph.number_of_nodes()} time:{end_time - start_time:.4f} seconds\")\n",
    "      start_time = end_time\n",
    "      del node_gdf\n",
    "      gc.collect()\n",
    "    elif file.stem.endswith(\"edges\"):\n",
    "      edge_gdf = load_file(file)\n",
    "      edge_gdf.apply(load_edge_from_gpd_row, axis=1, graph=graph)\n",
    "      end_time = time.perf_counter() \n",
    "      print(f\"file:{file} dfSize:{edge_gdf.shape[0]} graphSize:{graph.number_of_nodes()} time:{end_time - start_time:.4f} seconds\")\n",
    "      start_time = end_time\n",
    "      del edge_gdf\n",
    "      gc.collect()\n",
    "  return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_main_graph() -> None:\n",
    "  global main_graph\n",
    "  if main_graph is not None:\n",
    "    print(\"main_graph already loaded\")\n",
    "    return\n",
    "  pickle_file_path = Path('data') / 'main_graph.gpickle'\n",
    "  # load from binary, fastest\n",
    "  if pickle_file_path.exists():\n",
    "    print(\"loading from binary\")\n",
    "    with open(pickle_file_path, 'rb') as f:\n",
    "      main_graph = pickle.load(f)\n",
    "    return\n",
    "\n",
    "  # else, read from .fgb and dump as binary\n",
    "  print(\"loading from .fgb\")\n",
    "  main_graph = create_graph_from_node_and_edge_gdfs(Path('data') / 'new_graph')\n",
    "  print(\"dump graph to binary\")\n",
    "  with open(pickle_file_path, 'wb') as f:\n",
    "    pickle.dump(main_graph, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from binary\n"
     ]
    }
   ],
   "source": [
    "load_main_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2037029 10643539\n"
     ]
    }
   ],
   "source": [
    "print(main_graph.number_of_nodes(), main_graph.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, sin, cos, asin, sqrt\n",
    "\n",
    "def get_nodes_within_range(node: tuple[float, float], all_nodes: np.array, radius: float) -> list[tuple[float, float]]:\n",
    "  curr_node = np.array(node)\n",
    "  distance_array = np.linalg.norm(all_nodes - curr_node, axis=1)\n",
    "  return [tuple(row) for row in all_nodes[distance_array < radius]]\n",
    "\n",
    "def haversine_distance(coord1: tuple[float, float], coord2: tuple[float, float]):\n",
    "  R = 6372.8\n",
    "  lon1, lat1 = coord1 \n",
    "  lon2, lat2 = coord2\n",
    "  dLat = radians(lat2 - lat1)\n",
    "  dLon = radians(lon2 - lon1)\n",
    "  lat1 = radians(lat1)\n",
    "  lat2 = radians(lat2)\n",
    "\n",
    "  a = sin(dLat/2)**2 + cos(lat1)*cos(lat2)*sin(dLon/2)**2\n",
    "  c = 2*asin(sqrt(a))\n",
    "\n",
    "  return R * c\n",
    "\n",
    "def custom_distance(coord1: tuple[float, float], coord2: tuple[float, float]):\n",
    "  return geopy.distance.geodesic(coord1[::-1], coord2[::-1]).km\n",
    "\n",
    "def heuristics(coord1, coord2):\n",
    "  return custom_distance(coord1, coord2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_curve_polygon(start: dict, end: dict, buffer_dist: float, bezier_factor: float) -> Polygon:\n",
    "  start_xy = start['xy'][::-1]\n",
    "  end_xy = end['xy'][::-1]\n",
    "  start_cog = start['cog']\n",
    "  # end_cog = end['cog']\n",
    "\n",
    "  # Number of points along the curve\n",
    "  n_points = 15\n",
    "\n",
    "  # Convert COGs to radians for calculation\n",
    "  def cog_to_rad(cog):\n",
    "    return np.radians((450 - cog) % 360)\n",
    "\n",
    "  # Calculate control points for the Bezier curve\n",
    "  def calculate_control_points(start_xy, end_xy, start_cog, factor=bezier_factor):\n",
    "    # Convert COG to radians\n",
    "    start_cog_rad = cog_to_rad(start_cog)\n",
    "    \n",
    "    # Move the control points in the direction of the COGs\n",
    "    start_control = (start_xy[0] + factor * np.sin(start_cog_rad), start_xy[1] + factor * np.cos(start_cog_rad))\n",
    "    # Return control points\n",
    "    return [start_xy, start_control, end_xy]\n",
    "\n",
    "  # Calculate points along a quadratic Bezier curve\n",
    "  def bezier_curve(start_point, control_point_1, end_point, n_points=10):\n",
    "    points = []\n",
    "    for t in np.linspace(0, 1, n_points):\n",
    "      # Quadratic Bezier formula: B(t) = (1-t)^2 * P0 + 2(1-t)t * P1 + t^2 * P2\n",
    "      x = (1 - t)**2 * start_point[0] + 2 * (1 - t) * t * control_point_1[0] + t**2 * end_point[0]\n",
    "      y = (1 - t)**2 * start_point[1] + 2 * (1 - t) * t * control_point_1[1] + t**2 * end_point[1]\n",
    "      points.append((x, y))\n",
    "    return points\n",
    "\n",
    "  # Generate control points for the Bezier curve\n",
    "  control_points = calculate_control_points(start_xy, end_xy, start_cog)\n",
    "\n",
    "  # Generate points along the Bezier curve\n",
    "  bezier_points = bezier_curve(control_points[0], control_points[1], control_points[2], n_points)\n",
    "\n",
    "  # Create a Shapely LineString\n",
    "  line = LineString(bezier_points)\n",
    "  # Create a buffer around the LineString\n",
    "  buffered_area = line.buffer(buffer_dist)\n",
    "\n",
    "  # # Visualization of the Bezier curve and the points\n",
    "  # plt.figure(figsize=(10, 6))\n",
    "  # x, y = line.xy\n",
    "  # plt.plot(x, y, label=\"Bezier Curve\", color='blue', alpha=0.8)\n",
    "\n",
    "  # # Plot the start and end points\n",
    "  # plt.scatter([start_xy[0], end_xy[0]], [start_xy[1], end_xy[1]], color='red', label='Start and End Points')\n",
    "\n",
    "  # # Plot the control points\n",
    "  # control_x = [point[0] for point in control_points]\n",
    "  # control_y = [point[1] for point in control_points]\n",
    "  # plt.scatter(control_x, control_y, color='green', label='Control Points')\n",
    "\n",
    "  # # # Plot the Bezier points\n",
    "  # # bezier_x = [point[0] for point in bezier_points]\n",
    "  # # bezier_y = [point[1] for point in bezier_points]\n",
    "  # # plt.scatter(bezier_x, bezier_y, color='purple', label='Bezier Points', zorder=5)\n",
    "\n",
    "  # # Plot the buffer\n",
    "  # buffer_x, buffer_y = buffered_area.exterior.xy\n",
    "  # plt.fill(buffer_x, buffer_y, color='lightblue', alpha=0.5, label='Buffered Area')\n",
    "\n",
    "  # plt.title(\"Bezier Curve with Start, End, Control, and Bezier Points\")\n",
    "  # plt.xlabel(\"Longitude\")\n",
    "  # plt.ylabel(\"Latitude\")\n",
    "  # plt.legend(loc=\"upper left\", fontsize='small')\n",
    "  # plt.grid()\n",
    "  # plt.show()\n",
    "\n",
    "  return buffered_area\n",
    "\n",
    "def generate_straight_polygon(start_node: dict, end_node: dict, width: float) -> Polygon:\n",
    "  line = LineString([start_node['xy'][::-1], end_node['xy'][::-1]])\n",
    "  # bearing = Geodesic.WGS84.Inverse(start_node['latitude'], start_node['longitude'], end_node['latitude'], end_node['longitude'])['azi1']\n",
    "  return line.buffer(width)\n",
    "\n",
    "# # test: points with huge cog diff\n",
    "# start_point = {'xy': (10.790785, 57.761517), 'latitude': 57.761517, 'longitude': 10.790785, 'timestamp': 1730358512.0, 'sog': 8.4, 'cog': 4.4, 'draught': 5.4, 'ship_type': 'Cargo'}\n",
    "# end_point = {'xy': (10.591, 57.844828), 'latitude': 57.844828, 'longitude': 10.591, 'timestamp': 1730365204.0, 'sog': 5.4, 'cog': 263.8, 'draught': 5.4, 'ship_type': 'Cargo'}\n",
    "# generate_curve_polygon(start_point, end_point, 0.01, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input_trajectory(file_path: Path) -> list[dict]:\n",
    "  trajectory_points = []\n",
    "  with open(file_path.with_suffix('.txt'), 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "      latitude, longitude = float(row[\"latitude\"]), float(row[\"longitude\"]) \n",
    "      trajectory_points.append({\n",
    "        \"xy\": (longitude, latitude),\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"timestamp\": float(row[\"timestamp\"]),\n",
    "        \"sog\": float(row[\"sog\"]),\n",
    "        \"cog\": float(row[\"cog\"]),\n",
    "        \"draught\": float(row[\"draught\"]),\n",
    "        \"ship_type\": row[\"ship_type\"],\n",
    "      })\n",
    "  return trajectory_points\n",
    "\n",
    "def find_and_connect_with_possible_neighbors(\n",
    "  graph: nx.Graph,\n",
    "  node: tuple[float, float], \n",
    "  neighbor_radius: float, \n",
    "  kd_tree: spatial.KDTree,\n",
    ") -> set[tuple[float, float]]:\n",
    "  neighbor_nodes_idxs = kd_tree.query_ball_point(node, neighbor_radius)\n",
    "  added_nodes = set()\n",
    "  for idx in neighbor_nodes_idxs:\n",
    "    neighbor = tuple(kd_tree.data[idx])\n",
    "    if neighbor != node:\n",
    "      graph.add_node(neighbor, **graph.nodes[neighbor])\n",
    "      graph.add_edge(node, neighbor)\n",
    "      added_nodes.add(neighbor)\n",
    "  return added_nodes\n",
    "\n",
    "@time_function\n",
    "def build_kd_tree(graph: nx.Graph) -> spatial.KDTree:\n",
    "  return spatial.KDTree(graph.nodes())\n",
    "\n",
    "def estimate_gap_dist_and_cog(start_node: dict, end_node: dict) -> tuple[float, float]:\n",
    "  # speed unit: nautical mile / hour\n",
    "  avg_speed = (start_node[\"sog\"] + end_node[\"sog\"]) / 2.0\n",
    "  # time_diff unit: second\n",
    "  time_diff = end_node[\"timestamp\"] - start_node[\"timestamp\"]\n",
    "  # gap_distance_est unit: kilometer\n",
    "  gap_distance_est = avg_speed * 1.852 / 3600 * time_diff\n",
    "  # cog unit: degree\n",
    "  cog_diff = abs(start_node[\"cog\"] - end_node[\"cog\"])\n",
    "  cog_diff = min(cog_diff, 360 - cog_diff)\n",
    "  return gap_distance_est, cog_diff\n",
    "\n",
    "@time_function\n",
    "def find_path(\n",
    "  trajectory_nodes: list[dict],\n",
    "  graph: nx.Graph,\n",
    "  neighbor_radius: float,\n",
    "  trajectory_dist_threshold: float,\n",
    "  curve_buffer_dist: float,\n",
    "  straight_buffer_dist: float,\n",
    "  bezier_factor: float\n",
    ") -> tuple[list[tuple[float, float]], set, set]:\n",
    "  path = [(trajectory_nodes[0]['longitude'], trajectory_nodes[0]['latitude'])]\n",
    "  ship_draught = trajectory_nodes[0]['draught']\n",
    "  kd_tree = build_kd_tree(graph)\n",
    "  \n",
    "  # nodes to be removed after imputation to keep graph clean\n",
    "  to_be_removed_nodes = set()\n",
    "  # nodes that helps imputation\n",
    "  auxiliary_nodes = set()\n",
    "  # nodes found with astar search\n",
    "  imputed_nodes =set()\n",
    "  # input nodes from .txt file\n",
    "  input_nodes = set()\n",
    "  \n",
    "  # add input trajectory nodes to main graph\n",
    "  for node in trajectory_nodes:\n",
    "    xy = node['xy']\n",
    "    graph.add_node(xy, geometry=Point(*xy), sog=node['sog'], cog=node['cog'], draught=node['draught'])\n",
    "    to_be_removed_nodes.add(xy)\n",
    "    input_nodes.add(xy)\n",
    "\n",
    "  for i in tqdm(range(len(trajectory_nodes) - 1)):\n",
    "    start_node, end_node = trajectory_nodes[i], trajectory_nodes[i + 1]\n",
    "    start_pos = start_node['xy']\n",
    "    end_pos = end_node['xy']\n",
    "        \n",
    "    # points are too close, don't need imputation\n",
    "    geodesic_dist = custom_distance(start_pos, end_pos)\n",
    "    if geodesic_dist <= trajectory_dist_threshold:\n",
    "      path.append(end_pos)\n",
    "    else:\n",
    "      # try imputation\n",
    "      gap_distance_est, cog_diff = estimate_gap_dist_and_cog(start_node, end_node)\n",
    "      print(f\"gap_distance_est={gap_distance_est} geodesic_dist={geodesic_dist} cog_diff={cog_diff} division={gap_distance_est/geodesic_dist}\")\n",
    "      print(f\"start {start_node}\")\n",
    "      print(f\"end {end_node}\")\n",
    "      print(\"---------\")\n",
    "\n",
    "      # astar path must stay inside the genrated polygon\n",
    "      polygon = None\n",
    "      if cog_diff > 50:\n",
    "        polygon = generate_curve_polygon(start_node, end_node, curve_buffer_dist, bezier_factor)\n",
    "      else:\n",
    "        polygon = generate_straight_polygon(start_node, end_node, straight_buffer_dist)\n",
    "      \n",
    "      # add nodes to graph for printing\n",
    "      polygon_points = [point[::-1] for point in polygon.boundary.coords]\n",
    "      for new_node in polygon_points:\n",
    "        graph.add_node(new_node, geometry=Point(*new_node))\n",
    "      to_be_removed_nodes.update(polygon_points)\n",
    "      auxiliary_nodes.update(polygon_points)\n",
    "\n",
    "      # # plot polygan\n",
    "      # plt.figure(figsize=(10, 6))\n",
    "      # buffer_x, buffer_y = polygon.exterior.xy\n",
    "      # plt.fill(buffer_x, buffer_y, color='lightblue', alpha=0.5, label='Buffered Area')\n",
    "\n",
    "      # plt.title(\"Bezier Curve with Start, End, Control, and Bezier Points\")\n",
    "      # plt.xlabel(\"Longitude\")\n",
    "      # plt.ylabel(\"Latitude\")\n",
    "      # plt.legend(loc=\"upper left\", fontsize='small')\n",
    "      # plt.grid()\n",
    "      # plt.show()\n",
    "\n",
    "      neighbor_nodes = find_and_connect_with_possible_neighbors(graph, start_pos, neighbor_radius, kd_tree)\n",
    "      neighbor_nodes |= find_and_connect_with_possible_neighbors(graph, end_pos, neighbor_radius, kd_tree)\n",
    "      auxiliary_nodes |= neighbor_nodes\n",
    "\n",
    "      print(f\"number of new neighbor nodes: {len(neighbor_nodes)}\")\n",
    "\n",
    "      # define locally to take into account the polygon\n",
    "      def astar_weight(a, b, attrs):\n",
    "        # only check path that fall inside the polygon\n",
    "        if not polygon.contains(Point(*a[::-1])) or not polygon.contains(Point(*b[::-1])):\n",
    "          return None\n",
    "        if graph.nodes[a].get(\"draught\", ship_draught) < ship_draught or graph.nodes[b].get(\"draught\", ship_draught) < ship_draught:\n",
    "          return None\n",
    "        return custom_distance(a, b)\n",
    "      \n",
    "      try:\n",
    "        new_path = nx.astar_path(graph, start_pos, end_pos, heuristic=heuristics, weight=astar_weight)\n",
    "        imputed_nodes.update(new_path[1:-1])\n",
    "        path += new_path[1:] # exclude start point\n",
    "      except nx.NetworkXNoPath:\n",
    "        path.append(end_pos)\n",
    "        print(f\"ERROR: no astar path found between node {i} and node {i + 1}\")\n",
    "  return path, input_nodes, imputed_nodes, to_be_removed_nodes, auxiliary_nodes\n",
    "\n",
    "@time_function\n",
    "def generate_output_files_for_nodes(\n",
    "  nodes: list[tuple[float, float]],\n",
    "  graph: nx.Graph, \n",
    "  file_path: Path\n",
    ") -> None:\n",
    "  file_path.mkdir(parents=True, exist_ok=True)\n",
    "  node_features = [{\n",
    "    \"type\": \"Feature\",\n",
    "    \"geometry\": graph.nodes[node][\"geometry\"],\n",
    "    \"properties\": None\n",
    "  } for node in nodes]\n",
    "  # .fgb is faster than .geojson\n",
    "  gpd.GeoDataFrame.from_features(node_features).to_file(file_path.with_suffix('.fgb'))\n",
    "\n",
    "@time_function\n",
    "def generate_output_files_for_edges(\n",
    "  edges: list[list[list[float, float], list[float, float]]],\n",
    "  file_path: Path\n",
    ") -> None:\n",
    "  file_path.mkdir(parents=True, exist_ok=True)\n",
    "  edge_features = [{\n",
    "    \"type\": \"Feature\",\n",
    "    \"geometry\": {\n",
    "      \"type\": \"LineString\",\n",
    "      \"coordinates\": edge\n",
    "    },\n",
    "    \"properties\": None\n",
    "  } for edge in edges]\n",
    "  # .fgb is faster than .geojson\n",
    "  gpd.GeoDataFrame.from_features(edge_features).to_file(file_path.with_suffix('.fgb'))\n",
    "  \n",
    "\n",
    "def impute(\n",
    "  graph: nx.Graph,\n",
    "  input_file_path: Path,\n",
    "  output_file_path: Path,\n",
    "  trajectory_filename: list[dict], \n",
    "  neighbor_radius: float, \n",
    "  trajectory_dist_threshold: float,\n",
    "  curve_buffer_dist: float,\n",
    "  straight_buffer_dist: float,\n",
    "  bezier_factor: float\n",
    ") -> None:\n",
    "  trajectory_nodes = read_input_trajectory(input_file_path / trajectory_filename)\n",
    "  path, input_nodes, imputed_nodes, to_be_removed_nodes, auxiliary_nodes = find_path(\n",
    "    trajectory_nodes, graph, neighbor_radius, trajectory_dist_threshold, curve_buffer_dist, straight_buffer_dist, bezier_factor)\n",
    "  \n",
    "  updated_output_path = output_file_path / trajectory_filename\n",
    "\n",
    "  generate_output_files_for_nodes(list(input_nodes), graph, updated_output_path / 'input_nodes')\n",
    "  generate_output_files_for_nodes(list(imputed_nodes), graph, updated_output_path / 'imputed_nodes')\n",
    "  generate_output_files_for_nodes(list(auxiliary_nodes), graph, updated_output_path / 'auxiliary_nodes')\n",
    "  edges = [[(path[i]), list(path[i + 1])] for i in range(len(path) - 1)]\n",
    "  generate_output_files_for_edges(edges, updated_output_path / 'edges')\n",
    "\n",
    "  # remove added nodes to keep main graph clean\n",
    "  graph.remove_nodes_from(to_be_removed_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_kd_tree executed in 1.4390 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc6b69c4ed842deb6c7da4ec6b0b41b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gap_distance_est=19.6068925 geodesic_dist=18.70872021921221 cog_diff=20.499999999999986 division=1.0480082159690136\n",
      "start {'xy': (10.201972, 56.989898), 'latitude': 56.989898, 'longitude': 10.201972, 'timestamp': 1730330131.0, 'sog': 10.4, 'cog': 116.2, 'draught': 5.4, 'ship_type': 'Cargo'}\n",
      "end {'xy': (10.48242, 56.921013), 'latitude': 56.921013, 'longitude': 10.48242, 'timestamp': 1730334040.0, 'sog': 9.1, 'cog': 136.7, 'draught': 5.4, 'ship_type': 'Cargo'}\n",
      "---------\n",
      "number of new neighbor nodes: 346\n",
      "gap_distance_est=19.708881111111115 geodesic_dist=20.032519034183643 cog_diff=4.7 division=0.9838443721171426\n",
      "start {'xy': (10.735555, 57.291728), 'latitude': 57.291728, 'longitude': 10.735555, 'timestamp': 1730347372.0, 'sog': 8.9, 'cog': 1.2, 'draught': 5.4, 'ship_type': 'Cargo'}\n",
      "end {'xy': (10.757612, 57.471212), 'latitude': 57.471212, 'longitude': 10.757612, 'timestamp': 1730351582.0, 'sog': 9.3, 'cog': 5.9, 'draught': 5.4, 'ship_type': 'Cargo'}\n",
      "---------\n",
      "number of new neighbor nodes: 500\n",
      "gap_distance_est=23.754369333333337 geodesic_dist=15.072998992130785 cog_diff=100.59999999999997 division=1.5759550800563886\n",
      "start {'xy': (10.790785, 57.761517), 'latitude': 57.761517, 'longitude': 10.790785, 'timestamp': 1730358512.0, 'sog': 8.4, 'cog': 4.4, 'draught': 5.4, 'ship_type': 'Cargo'}\n",
      "end {'xy': (10.591, 57.844828), 'latitude': 57.844828, 'longitude': 10.591, 'timestamp': 1730365204.0, 'sog': 5.4, 'cog': 263.8, 'draught': 5.4, 'ship_type': 'Cargo'}\n",
      "---------\n",
      "number of new neighbor nodes: 507\n",
      "gap_distance_est=21.103540000000002 geodesic_dist=19.98526158738168 cog_diff=0.5999999999999943 division=1.0559551551391444\n",
      "start {'xy': (9.707735, 57.58804), 'latitude': 57.58804, 'longitude': 9.707735, 'timestamp': 1730392152.0, 'sog': 4.2, 'cog': 236.3, 'draught': 5.4, 'ship_type': 'Cargo'}\n",
      "end {'xy': (9.42957, 57.488918), 'latitude': 57.488918, 'longitude': 9.42957, 'timestamp': 1730401692.0, 'sog': 4.4, 'cog': 236.9, 'draught': 5.4, 'ship_type': 'Cargo'}\n",
      "---------\n",
      "number of new neighbor nodes: 468\n",
      "find_path executed in 34.8711 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Isaac\\.pyenv\\pyenv-win\\versions\\3.9.0\\lib\\site-packages\\pyogrio\\geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n",
      "c:\\Users\\Isaac\\.pyenv\\pyenv-win\\versions\\3.9.0\\lib\\site-packages\\pyogrio\\geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n",
      "c:\\Users\\Isaac\\.pyenv\\pyenv-win\\versions\\3.9.0\\lib\\site-packages\\pyogrio\\geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_output_files_for_nodes executed in 0.3895 seconds\n",
      "generate_output_files_for_nodes executed in 0.0339 seconds\n",
      "generate_output_files_for_nodes executed in 0.0681 seconds\n",
      "generate_output_files_for_edges executed in 0.3441 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Isaac\\.pyenv\\pyenv-win\\versions\\3.9.0\\lib\\site-packages\\pyogrio\\geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n"
     ]
    }
   ],
   "source": [
    "# trajectory_filename = 'aisdk-2024-10-31_Class_A_MMSI_314437000_4gaps_15km'\n",
    "trajectory_filename = 'aisdk-2024-10-31_Class_A_MMSI_209525000_4gaps_20km'\n",
    "# trajectory_filename = 'aisdk-2024-10-31_Class_A_MMSI_245250000_4gaps_15km'\n",
    "\n",
    "input_file_path = Path('data') / 'trajectory'\n",
    "output_file_path = Path('data') / 'new_output'\n",
    "output_file_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# params\n",
    "neighbor_radius = 0.0064\n",
    "trajectory_dist_threshold = 1 # unit km\n",
    "curve_buffer_dist = 0.01\n",
    "straight_buffer_dist = 0.03\n",
    "bezier_factor = 0.15\n",
    "\n",
    "impute(main_graph, input_file_path, output_file_path, trajectory_filename, neighbor_radius, trajectory_dist_threshold, curve_buffer_dist, straight_buffer_dist, bezier_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_geojson(dir: Path):\n",
    "  for file in dir.rglob('*.txt'):\n",
    "    trajectory_nodes = read_input_trajectory(file.name)\n",
    "    features = [{\n",
    "      \"type\": \"Feature\",\n",
    "      \"geometry\": Point(node['longitude'], node['latitude']),\n",
    "      \"properties\": None\n",
    "    } for node in trajectory_nodes]\n",
    "\n",
    "    node_gdf = gpd.GeoDataFrame.from_features(features)\n",
    "    input_file_geojson_path = dir / file.stem\n",
    "    node_gdf.to_file(input_file_geojson_path.with_suffix('.fgb'))  \n",
    "\n",
    "# csv_to_geojson(Path('data') / 'trajectory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
